# --------------------------------------
# Training parameters
# --------------------------------------
wandb_key: a012ea1e8f9db57d84ce1d02c2448e231e2bf452
model_name: lstm3_256
num_classes: 5
input_size: 96
embedder: en_core_web_sm
embedding: subsentence #sentence/word/subsentence
# --------------------------------------
# Knowledge Distillation
# --------------------------------------
distillation_type: none #none/soft/hard
teacher_model: mlp_1k_e30
distillation_alpha: 0.5
distillation_tau: 1
# --------------------------------------
# Testing parameters
# --------------------------------------
test_models: all
# --------------------------------------
# Optimizer parameters
# --------------------------------------
opt: adamw
weight_decay: 0.01
momentum: 0.9
epochs: 30
#slimming_bn_s: 0.001
# --------------------------------------
# Learning rate schedule parameters
# --------------------------------------
sched: cosine
lr: 0.0005
warmup_lr: 0.00001
min_lr: 0.00005
warmup_epochs: 3